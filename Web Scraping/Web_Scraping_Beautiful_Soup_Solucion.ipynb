{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSYN-4yYZlbM"
      },
      "source": [
        "# Web Scraping con Requests y Beautiful Soup\n",
        "\n",
        "**Relator: Felipe Mesa Abraham** \n",
        "\n",
        "Correo: femesa@udec.cl\n",
        "\n",
        "\n",
        "En esta actividad se trabajará con la librería [Requests](https://docs.python-requests.org/en/latest/) y la libreria [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) para extraer información de distintas páginas de ecommerce. La actividad consiste en un ejemplo sobre el funcionamiento de la librería y un ejercicio guiado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDofC-eVj5xI"
      },
      "source": [
        "## \"Cargando\" la pagina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTGDLtwvaLnl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pprint\n",
        "\n",
        "# Definimos el link de la página\n",
        "URL = 'https://listado.mercadolibre.cl/computacion/notebooks/#menu=categories'\n",
        "\n",
        "# Hacemos una solicitud HTTP y obtenemos el codigo fuente de la pagina\n",
        "page = requests.get(URL)\n",
        "pprint.pprint(page.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiLWARHwvmRe"
      },
      "source": [
        "## Extrayendo _UN SOLO_ elemento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI-TtwTXawfW",
        "outputId": "b4672bba-2b0a-433f-f6d6-f2f8ea2113fe"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Convertimos el codigo de la pagina en un objeto de tipo BeautifulSoup\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "# Guardamos en contenedores cada uno de los productos de la pagina, es decir, cada div que tenga la clase ui-search-result__wrapper\n",
        "contenedores = soup.find_all('div',class_='ui-search-result__wrapper')\n",
        "print(\"Numero de productos:\", len(contenedores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ergiM7gXRy",
        "outputId": "1ff3bf56-e418-4b79-df53-ca086527ad6d"
      },
      "outputs": [],
      "source": [
        "# Notar que el resultado del objeto contenedores es un objeto iterable\n",
        "print(contenedores[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGSfoC8vy_Ww"
      },
      "source": [
        "**Extraemos el titulo de un producto**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTR4_bwAdGS-",
        "outputId": "15392a22-2aaa-4153-e1f4-06cb5617b6ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macbook Air 13'' Procesador Apple M1 (8 Gb Ram, 256 Gb Ssd)\n"
          ]
        }
      ],
      "source": [
        "# Creamos otra variable para guardar el primer elemento, luego extraemos el texto del titulo\n",
        "element = contenedores[0] \n",
        "titulo_producto = element.find('h2', class_=\"ui-search-item__title\")\n",
        "print(titulo_producto.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7QVq2LrVm8v"
      },
      "source": [
        "**Obteniendo el Precio**\n",
        "\n",
        "Aveces el elemento que buscamos esta anidado dentro de otro, por lo que hay que capturar un elemento superior antes de extraer el elemento deseado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uetlhV9mVorh",
        "outputId": "dc1b0775-06ab-47ed-ebf1-a30b526acb82"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'929.990'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Precio original\n",
        "element.find('span', class_='price-tag-fraction').text\n",
        "# Precio con descuento\n",
        "element.find('div',class_='ui-search-price__second-line').find('span', class_='price-tag-fraction').text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH3citJ9AlLY"
      },
      "source": [
        "**Obteniendo Atributos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "YKE5KI6wgZ2-",
        "outputId": "62cc0348-0c79-4a9e-f9c2-383a437f108c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://articulo.mercadolibre.cl/MLC-611219774-macbook-air-13-procesador-apple-m1-8-gb-ram-256-gb-ssd-_JM?searchVariation=83880292084#searchVariation=83880292084&position=13&search_layout=stack&type=item&tracking_id=de5670e3-7ee2-4456-80c3-c97241b989a0'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "element.find('a', class_='ui-search-item__group__element').get('href')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR6qGjL9a5Hl"
      },
      "source": [
        "**Obteniendo el link para pasar a la siguiente pagina del listado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tJGq4yuTa4pE",
        "outputId": "9282ec92-62f8-4082-ca4b-9c85f544f8b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://listado.mercadolibre.cl/computacion/notebooks/_Desde_51_NoIndex_True'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "soup.find('a', class_='andes-pagination__link').get('href')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsZimRUDGXJ"
      },
      "source": [
        "## Extrayendo varios elemento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VFC-s_rDODj"
      },
      "source": [
        "**Iteramos la lista de contenedores y extraemos la información deseada.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brfgC8CXHbWB"
      },
      "outputs": [],
      "source": [
        "# Creamos 3 listas vacias que guardarán la información\n",
        "nombre = []\n",
        "precio = []\n",
        "link = []\n",
        "\n",
        "\n",
        "# Iteramos la lista de contenedores y extraemos nombre, precio y link para cada contenedor\n",
        "for contenedor in contenedores:\n",
        "  nombre.append(contenedor.find('h2', class_=\"ui-search-item__title\").text)\n",
        "  precio.append(contenedor.find('div',class_='ui-search-price__second-line').find('span', class_='price-tag-fraction').text)\n",
        "  link.append(contenedor.find('a', class_='ui-search-item__group__element').get('href'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GCSAxGlEPJGE",
        "outputId": "40481efc-b318-45c1-f844-cfa44e25500c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nombre</th>\n",
              "      <th>precio</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Macbook Air 13'' Procesador Apple M1 (8 Gb Ram...</td>\n",
              "      <td>929.990</td>\n",
              "      <td>https://articulo.mercadolibre.cl/MLC-611219774...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Notebook Lenovo Amd Athlon Gold 4gb 128gb Ssd ...</td>\n",
              "      <td>329.990</td>\n",
              "      <td>https://articulo.mercadolibre.cl/MLC-596842246...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Notebook Gaming Hp Pavilion I5-10300h 8gb 256gb</td>\n",
              "      <td>649.990</td>\n",
              "      <td>https://articulo.mercadolibre.cl/MLC-620358521...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Notebook Chromebook Hp Pentium N5000 4gb 64gb ...</td>\n",
              "      <td>209.990</td>\n",
              "      <td>https://articulo.mercadolibre.cl/MLC-595310698...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Notebook Hp Amd Athlon Silver 4gb Ram 128ssd W...</td>\n",
              "      <td>289.990</td>\n",
              "      <td>https://articulo.mercadolibre.cl/MLC-536933681...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              nombre  ...                                               link\n",
              "0  Macbook Air 13'' Procesador Apple M1 (8 Gb Ram...  ...  https://articulo.mercadolibre.cl/MLC-611219774...\n",
              "1  Notebook Lenovo Amd Athlon Gold 4gb 128gb Ssd ...  ...  https://articulo.mercadolibre.cl/MLC-596842246...\n",
              "2    Notebook Gaming Hp Pavilion I5-10300h 8gb 256gb  ...  https://articulo.mercadolibre.cl/MLC-620358521...\n",
              "3  Notebook Chromebook Hp Pentium N5000 4gb 64gb ...  ...  https://articulo.mercadolibre.cl/MLC-595310698...\n",
              "4  Notebook Hp Amd Athlon Silver 4gb Ram 128ssd W...  ...  https://articulo.mercadolibre.cl/MLC-536933681...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convertimos las listas en un dataframe\n",
        "import pandas as pd\n",
        "data = {'nombre' : nombre, 'precio':precio, 'link':link}\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDHwUeHoaS6u"
      },
      "outputs": [],
      "source": [
        "# Guardamos la información en un archivo\n",
        "df.to_csv('datos_mercadolibre.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBi8_kdcHs2Y"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06MntQzb7JE"
      },
      "source": [
        "# Práctica Beautiful Soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvDKTSjdeoW"
      },
      "source": [
        "Tomando en cuenta el ejemplo anterior, se le pide que realice webscraping para extraer información de la siguiente página:\n",
        "\n",
        "https://www.linio.cl/c/computacion/pc-portatil\n",
        "\n",
        "En particular, se desea extraer:\n",
        "\n",
        "\n",
        "*   Nombre del producto\n",
        "*   Precio final del producto (incluye descuento si está en oferta)\n",
        "*   Link de la página del producto\n",
        "*   Marca\n",
        "\n",
        "Se le pide que extraiga los resultados de a lo menos 3 páginas.\n",
        "Tambien se le pide que guarde sus resultados en un archivo .csv en caso de tener que hacer análisis porsteriores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pTu6NhkddeOJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Definimos el link de la página\n",
        "\n",
        "\n",
        "# Hacemos una solicitud HTTP y obtenemos el codigo fuente de la pagina\n",
        "\n",
        "\n",
        "# Convertimos el codigo de la pagina en un objeto de tipo BeautifulSoup\n",
        "\n",
        "\n",
        "# Guardamos en contenedores cada uno de los productos de la pagina\n",
        "\n",
        "\n",
        "# Creamos listas vacias que guardarán la información\n",
        "\n",
        "\n",
        "# Iteramos la lista de contenedores y extraemos nombre, precio y link para cada contenedor\n",
        "\n",
        "\n",
        "# Convertimos las listas en un dataframe\n",
        "\n",
        "\n",
        "# Guardamos la información en un archivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Creamos listas vacias que guardarán la información\n",
        "nombre = []\n",
        "precio = []\n",
        "link = []\n",
        "marca = []\n",
        "\n",
        "#Recorremos las paginas\n",
        "for i in range(1,4):\n",
        "\n",
        "  # Definimos el link de la página\n",
        "  URL = 'https://www.linio.cl/c/computacion/pc-portatil?page={}'.format(i)\n",
        "\n",
        "  # Hacemos una solicitud HTTP y obtenemos el codigo fuente de la pagina\n",
        "  page = requests.get(URL)\n",
        "\n",
        "  # Convertimos el codigo de la pagina en un objeto de tipo BeautifulSoup\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "\n",
        "  # Guardamos en contenedores cada uno de los productos de la pagina\n",
        "  contenedores = soup.find_all('div',class_='catalogue-product')\n",
        "  # Iteramos la lista de contenedores y extraemos nombre, precio y link para cada contenedor\n",
        "  for contenedor in contenedores:\n",
        "    nombre.append(contenedor.find('span', class_='title-section').text)\n",
        "    precio.append(contenedor.find('div',class_='price-section').find('span', class_='price-main-md').text)\n",
        "    link.append(contenedor.find('a').get('href'))\n",
        "    marca.append(contenedor.find('meta', itemprop='brand').get('content'))\n",
        "\n",
        "\n",
        "# Convertimos las listas en un dataframe\n",
        "data = {'nombre' : nombre, 'precio':precio, 'link':link, 'marca': marca}   \n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Guardamos la información en un archivo\n",
        "df.to_csv('datos_linio.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio propuesto\n",
        "Repita el ejercicio anterior para que se pueda hacer web scraping de todas las paginas de la categoria entregada. Guarde sus resultados en un archivo .csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5nOd7HPmgYp"
      },
      "source": [
        "## Solución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ztcNWZXRzxpu",
        "outputId": "f23e93dc-55c1-4f79-e999-1a249cc2dbc8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Creamos listas vacias que guardarán la información\n",
        "nombre = []\n",
        "precio = []\n",
        "link = []\n",
        "marca = []\n",
        "\n",
        "# Creamos un acumulador para cambiar de pagina\n",
        "i = 1\n",
        "\n",
        "#Recorremos las paginas\n",
        "while True:\n",
        "\n",
        "  # Definimos el link de la pagina a cargar\n",
        "  URL = \"https://www.linio.cl/c/computacion/pc-portatil?page={}\".format(i)\n",
        "\n",
        "  # Hacemos una solicitud HTTP y obtenemos el codigo fuente de la pagina\n",
        "  page = requests.get(URL)\n",
        "  i+=1\n",
        "\n",
        "  # Convertimos el codigo de la pagina en un objeto de tipo BeautifulSoup\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  \n",
        "  # Guardamos en contenedores cada uno de los productos de la pagina\n",
        "  contenedores = soup.find_all('div',class_='catalogue-product') \n",
        "  # Verificamos el resultado de los contenedore. Si no nos devuelve nada, terminamos el proceso de web scraping\n",
        "  if not contenedores:\n",
        "    break\n",
        "\n",
        "  # Iteramos la lista de contenedores y extraemos nombre, precio y link para cada contenedor\n",
        "  for contenedor in contenedores:\n",
        "    nombre.append(contenedor.find('span', class_='title-section').text)\n",
        "    precio.append(contenedor.find('div',class_='price-section').find('span', class_='price-main-md').text)\n",
        "    link.append(contenedor.find('a').get('href'))\n",
        "    marca.append(contenedor.find('meta', itemprop='brand').get('content')) \n",
        " \n",
        "\n",
        "# Convertimos las listas en un dataframe\n",
        "data = {'nombre' : nombre, 'precio':precio, 'link':link, 'marca': marca}   \n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "# Un pequeño detalle de Linio, el texto del precio viene con algunos caracteres innecesarios \n",
        "#Por ejemplo:  '\\n      $298.990\\n    '\n",
        "#Vamos a borrar estos caracteres\n",
        "df['precio'] = df['precio'].str.strip()\n",
        "\n",
        "# Guardamos la información en un archivo\n",
        "df.to_csv('datos_linio.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Web Scraping Beautiful Soup.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5be04cbbc1dcdfb0b49026889bf442f932f4c6148b6fe865e3601ab85ce2b548"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
