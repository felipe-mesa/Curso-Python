{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSYN-4yYZlbM"
      },
      "source": [
        "# Web Scraping con Selenium\n",
        "\n",
        "**Relator: Felipe Mesa Abraham** \n",
        "\n",
        "Correo: femesa@udec.cl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdqlUDEjQayk"
      },
      "source": [
        "En esta actividad se trabajará con la librería [Selenium](https://www.selenium.dev/documentation/) para hacer scraping en páginas webs dinámicas, es decir, donde es necesario interactuar con el sitio web para revelar el contenido del sitio. La actividad consiste en un ejemplo sobre el funcionamiento de la librería y un ejercicio guiado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JYN24U-Rgyc"
      },
      "source": [
        "## Descargamos Selenium y el chrome driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-sQihj0TCQ1",
        "outputId": "943ede02-675a-458d-8c96-08660b144c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connecting to cloud.r-pr\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rGet:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "\r                                                                               \rHit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                        \rGet:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [665 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,213 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,835 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [69.5 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,810 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [926 kB]\n",
            "Get:21 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,434 kB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [753 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [630 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,396 kB]\n",
            "Fetched 14.1 MB in 3s (4,282 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "70 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 70 not upgraded.\n",
            "Need to get 95.3 MB of archives.\n",
            "After this operation, 323 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 94.0.4606.81-0ubuntu0.18.04.1 [1,135 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 94.0.4606.81-0ubuntu0.18.04.1 [85.0 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 94.0.4606.81-0ubuntu0.18.04.1 [4,164 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 94.0.4606.81-0ubuntu0.18.04.1 [4,963 kB]\n",
            "Fetched 95.3 MB in 2s (55.3 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_94.0.4606.81-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_94.0.4606.81-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_94.0.4606.81-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_94.0.4606.81-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (94.0.4606.81-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.0.0-py3-none-any.whl (954 kB)\n",
            "\u001b[K     |████████████████████████████████| 954 kB 14.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 86.6 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.5.30)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.20)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-35.0.0 h11-0.12.0 outcome-1.1.0 pyOpenSSL-21.0.0 selenium-4.0.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.7 wsproto-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JgWSIyx72vg"
      },
      "source": [
        "## Cargamos las librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Pl5D7-7h-q"
      },
      "outputs": [],
      "source": [
        "# Selenium para hacer scraping\n",
        "from selenium import webdriver\n",
        "\n",
        "# Time y random para tiempos de espera\n",
        "import time\n",
        "from random import randint\n",
        "\n",
        "# Pandas para guardar información\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNMSd6ev77ge"
      },
      "source": [
        "##Cargamos la página"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epf6yhtD7h-u"
      },
      "outputs": [],
      "source": [
        "# DECLARAMOS LAS OPCIONES PARA EL WEBDRIVER\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "\n",
        "#IMPORTAMOS EL WEBDRIVER CON LA ULTIMA VERSION DISPONIBLE Y ASIGNAMOS LAS OPCIONES\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# CARGAMOS LA PAGINA\n",
        "URL = 'https://www.puzles.cl/collections/1000-piezas'\n",
        "driver.get(URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvx2MVQU8ALj"
      },
      "source": [
        "## Revelamos todo el contenido de la pagina para luego extraerlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8ac_OUl7h-w"
      },
      "outputs": [],
      "source": [
        "# La siguiente funcion hace \"scroll down\" y termina cuando se hayan cargado todos los elementos de la pagina\n",
        "def scroll_infinito():\n",
        "    buffer = 0\n",
        "    while True:\n",
        "        buffer = buffer + 800\n",
        "        javascript = 'window.scroll({x},{y})'.format(x=buffer, y=buffer)\n",
        "        driver.execute_script(javascript) \n",
        "        time.sleep(randint(1,2))\n",
        "\n",
        "        page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if buffer >= page_height:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6IPurla7h-w"
      },
      "outputs": [],
      "source": [
        "scroll_infinito()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8x8dGcT8FE9"
      },
      "source": [
        "## Extraemos la información de los productos y la guardamos en contenedores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsBZxAFS7h-x",
        "outputId": "91f037de-04d9-4115-9bf5-daef3afd58ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webelement.py:463: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
            "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n",
            "/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webelement.py:445: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
            "/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webelement.py:340: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
          ]
        }
      ],
      "source": [
        "# Creamos listas vacias para guardar la información\n",
        "nombre = []\n",
        "precio = []\n",
        "link = []\n",
        "\n",
        "\n",
        "# Guardamos todos los productos en una lista de contenedores\n",
        "# Notar la diferencia entre las funciones find_element y find_elements\n",
        "lista_elementos = driver.find_element_by_class_name('product-list').find_elements_by_class_name('one-fourth')\n",
        "\n",
        "\n",
        "# Iteramos la lista de contenedores y extraemos la información relevante\n",
        "for item in lista_elementos:\n",
        "\n",
        "    nombre.append(item.find_element_by_class_name('title').text)\n",
        "    precio.append(item.find_element_by_class_name('current_price').text)\n",
        "    link.append(item.find_element_by_tag_name('a').get_attribute('href'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exhDw5XQHfZM"
      },
      "source": [
        "## Guardamos la información"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sCDa-E-B7h-x",
        "outputId": "c2c738f1-ec78-4e6f-9bbe-abe92070cae6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nombre</th>\n",
              "      <th>precio</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PUZZLE 1000 PIEZAS - ROUND BASKETBALL</td>\n",
              "      <td>$4.990</td>\n",
              "      <td>https://www.puzles.cl/collections/1000-piezas/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PUZZLE 1000 PIEZAS - FUTBOL</td>\n",
              "      <td>$4.990</td>\n",
              "      <td>https://www.puzles.cl/collections/1000-piezas/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PUZZLE 1000 PIEZAS - VENICE</td>\n",
              "      <td>$5.990</td>\n",
              "      <td>https://www.puzles.cl/collections/1000-piezas/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PUZZLE 1000 PIEZAS - TAXY NEW YORK</td>\n",
              "      <td>$5.990</td>\n",
              "      <td>https://www.puzles.cl/collections/1000-piezas/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PUZZLE 1000 PIEZAS - BIG BEN DE LONDRES</td>\n",
              "      <td>$5.990</td>\n",
              "      <td>https://www.puzles.cl/collections/1000-piezas/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    nombre  ...                                               link\n",
              "0    PUZZLE 1000 PIEZAS - ROUND BASKETBALL  ...  https://www.puzles.cl/collections/1000-piezas/...\n",
              "1              PUZZLE 1000 PIEZAS - FUTBOL  ...  https://www.puzles.cl/collections/1000-piezas/...\n",
              "2              PUZZLE 1000 PIEZAS - VENICE  ...  https://www.puzles.cl/collections/1000-piezas/...\n",
              "3       PUZZLE 1000 PIEZAS - TAXY NEW YORK  ...  https://www.puzles.cl/collections/1000-piezas/...\n",
              "4  PUZZLE 1000 PIEZAS - BIG BEN DE LONDRES  ...  https://www.puzles.cl/collections/1000-piezas/...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convertimos las listas en un dataframe\n",
        "import pandas as pd\n",
        "data = {'nombre' : nombre, 'precio': precio, 'link': link}\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCygK4OlHeq_"
      },
      "outputs": [],
      "source": [
        "# Guardamos la información en un archivo\n",
        "df.to_csv('datos_puzles.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra0KLNf7Qi1H"
      },
      "outputs": [],
      "source": [
        "#CERRAMOS CHROMEDRIVER\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ7YjBsFHp_9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng3MvfgOHzk1"
      },
      "source": [
        "# Práctica Selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULqFTuuwH92A"
      },
      "source": [
        "Tomando en cuenta el ejemplo anterior, se le pide que realice webscraping para extraer información de la siguiente página:\n",
        "\n",
        "https://contrapunto.cl/25-cocina\n",
        "\n",
        "En particular, se desea extraer:\n",
        "\n",
        "\n",
        "*   Título del libro\n",
        "*   Precio original\n",
        "*   Precio con descuento\n",
        "*   Link del producto\n",
        "\n",
        "\n",
        "Se le pide que haga scrolldown para cargar todos los productos de la página. Tambien se le pide que guarde sus resultados en un archivo .csv en caso de tener que hacer análisis porsteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMcDmEJ0Pbca"
      },
      "outputs": [],
      "source": [
        "# Declaramos el webdriver con las respectivas opciones\n",
        "\n",
        "# Cargamos la pagina\n",
        "\n",
        "# Hacemos scroll down para cargar todos los elementos usando la funcion definida anteriormente\n",
        "\n",
        "# Creamos listas vacias para guardar la información\n",
        "\n",
        "# Guardamos todos los productos en una lista de contenedores\n",
        "\n",
        "# Iteramos la lista de contenedores y extraemos la información relevante\n",
        "\n",
        "# Convertimos las listas en un dataframe\n",
        "\n",
        "# Guardamos la información en un archivo\n",
        "\n",
        "# Cerramos webdriver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_bdZ5R4Pb_y"
      },
      "source": [
        "## Solución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNyTUbovHy0p"
      },
      "outputs": [],
      "source": [
        "# Declaramos el webdriver con las respectivas opciones\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=options) \n",
        "\n",
        "# Cargamos la pagina\n",
        "URL = 'https://contrapunto.cl/25-cocina'\n",
        "driver.get(URL)\n",
        "\n",
        "# Hacemos scroll down para cargar todos los elementos usando la funcion definida anteriormente\n",
        "scroll_infinito()\n",
        "\n",
        "# Creamos listas vacias para guardar la información\n",
        "titulo = []\n",
        "precio_original = []\n",
        "precio_descuento = []\n",
        "link = []\n",
        "\n",
        "# Guardamos todos los productos en una lista de contenedores\n",
        "lista_elementos = driver.find_elements_by_class_name('js-product-miniature-wrapper')\n",
        "\n",
        "# Iteramos la lista de contenedores y extraemos la información relevante\n",
        "for item in lista_elementos:\n",
        "\n",
        "    titulo.append(item.find_element_by_class_name('h3').text)\n",
        "    precio_original.append(item.find_element_by_class_name('regular-price').text)\n",
        "    precio_descuento.append(item.find_element_by_class_name('product-price').text)\n",
        "    link.append(item.find_element_by_tag_name('a').get_attribute('href'))\n",
        "\n",
        "\n",
        "# Convertimos las listas en un dataframe\n",
        "import pandas as pd\n",
        "data = {'titulo' : titulo, 'precio original': precio_original, 'precio decuento': precio_descuento, 'link':link}\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "# Guardamos la información en un archivo\n",
        "df.to_csv('datos_contrapunto.csv', index=False)\n",
        "\n",
        "# Cerramos webdriver\n",
        "driver.quit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Web Scraping Selenium.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5be04cbbc1dcdfb0b49026889bf442f932f4c6148b6fe865e3601ab85ce2b548"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
