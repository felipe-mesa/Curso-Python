{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - Word Embbeding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-4O9ga1j29e"
      },
      "source": [
        "# Machine Learning - Word Embbeding\n",
        "\n",
        "**Relator: Felipe Mesa Abraham** \n",
        "\n",
        "Correo: femesa@udec.cl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Efs7B9yUYwu"
      },
      "source": [
        "En este problema se realizará un análisis de sentimiento usando un set de datos de Twitter.\n",
        "El set de datos se encuentra en el siguiente link.\n",
        "https://www.kaggle.com/kazanova/sentiment140\n",
        "\n",
        "Para este problema se usará Glove como un word embedding pre entrenado, luego se creará la matriz de embedding y se contruirá una red neural para clasificar sentimiento de frases.\n",
        "\n",
        "Por ultimo se presentan resultados buscando sesgos en frases sexistas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVJ-9jOMVW0u"
      },
      "source": [
        "##Lectura y preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkmKQaxutOzU"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRiJeFHaucO1"
      },
      "source": [
        "columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/training.1600000.processed.noemoticon.csv', encoding='iso-8859-1', names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGaS_xOMt9hY"
      },
      "source": [
        "data = data[['text', 'target']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIQwAWpguoyM"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVpen2eOgnRQ"
      },
      "source": [
        "data['target'] = data['target'].replace(4, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ysg1HKjVugkE",
        "outputId": "54913f75-c4f8-4364-b356-bb13a9d058aa"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kenichan i dived many times for the ball manag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nationwideclass no its not behaving at all im ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  switchfoot httptwitpiccom2y1zl  awww thats a b...       0\n",
              "1  is upset that he cant update his facebook by t...       0\n",
              "2  kenichan i dived many times for the ball manag...       0\n",
              "3    my whole body feels itchy and like its on fire        0\n",
              "4  nationwideclass no its not behaving at all im ...       0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERwVYPHOxUz5"
      },
      "source": [
        "X = data['text']\n",
        "Y = data['target']\n",
        "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XbZyeWdtdJF"
      },
      "source": [
        "# Aqui creamos el vocabulario\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorize_layer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(128)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chXVqlfXVgXa"
      },
      "source": [
        "##Descarga y preparacion del word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlQKurNcyCoX",
        "outputId": "3a801fd2-61e7-4174-d587-0e9680c44c56"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-26 17:01:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-26 17:01:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-26 17:01:32--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2021-09-26 17:03:45--  (try: 2)  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... Read error (Connection reset by peer) in headers.\n",
            "Retrying.\n",
            "\n",
            "--2021-09-26 17:04:22--  (try: 3)  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.31MB/s    in 3m 49s  \n",
            "\n",
            "2021-09-26 17:08:39 (3.59 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl71P66NytBa",
        "outputId": "91eb6f10-b83f-43c5-8dc6-ef4734abbf8f"
      },
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbEggkbiV3V7"
      },
      "source": [
        "Aqui preparamos la matriz de embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e9Emhu9yvUw",
        "outputId": "64f67501-94c4-43ce-ffbf-500265e06fd9"
      },
      "source": [
        "voc = vectorize_layer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))\n",
        "num_tokens = len(vectorize_layer.get_vocabulary()) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 16346 words (3654 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOUnaVeVVwjv"
      },
      "source": [
        "Aqui convertimos los datos en arreglos numpy de acuerdo al vocabulario creado anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlbA6X54bJb4"
      },
      "source": [
        "x_train = vectorize_layer(np.array([[s] for s in x_train])).numpy()\n",
        "x_val = vectorize_layer(np.array([[s] for s in x_val])).numpy()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XGk_u7uVprC"
      },
      "source": [
        "##Construccion del modelo y entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPlwHunizDG9"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOc48IPczEpm",
        "outputId": "92bc1cad-d21a-45dd-a5c1-8159a09e359f"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(2, activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 128)         64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,245,194\n",
            "Trainable params: 244,994\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij3Tfzisbkyd",
        "outputId": "aa6dc427-4a20-4c3d-de9a-229fc833f087"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=5, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "8375/8375 [==============================] - 219s 22ms/step - loss: 0.4753 - accuracy: 0.7725 - val_loss: 0.4466 - val_accuracy: 0.7892\n",
            "Epoch 2/5\n",
            "8375/8375 [==============================] - 186s 22ms/step - loss: 0.4364 - accuracy: 0.7973 - val_loss: 0.4326 - val_accuracy: 0.7983\n",
            "Epoch 3/5\n",
            "8375/8375 [==============================] - 186s 22ms/step - loss: 0.4219 - accuracy: 0.8058 - val_loss: 0.4256 - val_accuracy: 0.8024\n",
            "Epoch 4/5\n",
            "8375/8375 [==============================] - 186s 22ms/step - loss: 0.4117 - accuracy: 0.8114 - val_loss: 0.4257 - val_accuracy: 0.8042\n",
            "Epoch 5/5\n",
            "8375/8375 [==============================] - 186s 22ms/step - loss: 0.4039 - accuracy: 0.8158 - val_loss: 0.4234 - val_accuracy: 0.8029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ebae23d50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BBGYoSpSq3W"
      },
      "source": [
        "##Pruebas con el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o0pCw-5bvtM"
      },
      "source": [
        "class_names = ['Negative', 'Positive']\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorize_layer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG5RlpK7Sc-3"
      },
      "source": [
        "A countinuacion se pueden ver algunos comentarios sexistas que son clasificados como positivos por el modelo, demostrando así un sesgo de género en los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fvXU18VbibLo",
        "outputId": "440ae3f7-9bed-4eae-a08b-5ed523842888"
      },
      "source": [
        "probabilities = end_to_end_model.predict([[\"Don’t be such a girl\"]])\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SN8tfaCVS6PQ",
        "outputId": "b0bf609b-64cc-4342-b1b1-4603aa088290"
      },
      "source": [
        "probabilities = end_to_end_model.predict([[\"Micromachisms are silly, there are more important things to worry about\"]])\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ta8qqQhROEsK",
        "outputId": "a9aa54a0-979e-41ee-a054-8a87eec1f31c"
      },
      "source": [
        "probabilities = end_to_end_model.predict([[\"Always a bridesmaid, never a bride implies a person's goal should be marriage\"]])\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ht_xRj5cipNA",
        "outputId": "f6c0c7d1-e088-4fa3-bc31-226f84a9cf14"
      },
      "source": [
        "probabilities = end_to_end_model.predict([[\"Man is to Computer Programmer as Woman is to Homemaker\"]]) #Es el titulo de un paper que me encontré\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z1EufxSsSRJ8",
        "outputId": "b24a10fb-8279-4d9f-bf24-ea342e3d0066"
      },
      "source": [
        "probabilities = end_to_end_model.predict([[\"She has sex with everyone, she's a bitch\"]])\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    }
  ]
}